Related Work

Back in 2005, a social navigation system for browsing food recipes as well as choosing recipes based on ingredients and their “ related” cuisine was first seen in the work of Svenssonal et al. [1] Later, Forbes and Zhu [2] improved the model by suggesting recipes based on the previous ratings and experience of the users. After successful experiments on the model, it was shown their work not only gave more efficiency, but also helped in more accurate recipe recommendation. In 2010, a hybrid model for recipe search and recommendation was proposed by Xie el al.[3] Afterwards, Shidochi el al.[4] introduced a creative work into the classification of ingredients and recipe generation. His algorithm could extract ingredients that were replaceable with healthier options which satisfies constraints like calorie intake and nutritional value. However, none of these models could achieve a 70% accuracy rate because they did not pay attention towards finding the correlation between the group of ingredients and a cuisine. Here, we are trying to develop a model that identifies the cuisine based on the given ingredients. Some of the useful techniques/classifiers are listed below, alone with the evaluations.
One of the most basic and popular tools for text data pattern discovery is frequency analysis, which handles the text information based on the frequency of occurrences of the tokens. In this case, Term Frequency (TF) and Inverse Document Frequency (IDF) can be implemented. However, the weakness of this method is that the appearance of each token is assumed to depend only on the concept, and thus the word-sequence information is discarded. The accuracy could be unsatisfactory as it does not associate different ingredients in our recipes.
Since the objective of this project is to classify the recipes, some of the advanced text analysis techniques can be used here. One of the techniques is Decision Tree (DT), which is a very popular machine learning algorithm by transforming the data into a tree representation. The advantage of this method is the minimal requirement of data preprocessing, but the disadvantage is the demand of time complexity. Compared to other algorithms, DT can go far more complex which often involves expensive time complexity.
Another classification method is the Naïve Bayes classifier (NB), which is a simple ‘probabilistic classifier’ based on applying Bayes’s theorem with strong independence assumptions between the features. This algorithm works quickly and saves a lot of time, however, the limit of the applicability comes from the assumption of independence. In our case, this algorithm might not be the ideal option as NB works well for a simple classification such as identifying fruits as Orange or NOT Orange, but we have more than 100 cuisines as categories, and Naïve Bayes seems too naïve. However, a previous study on the similar topic has shown this method has an accuracy rate of 73.5%, which is considered a good predictive model.[5]
Another classifying tool is Support Vector Machine (SVM), which is a supervised machine learning algorithm that plots a data item as a point in n-dimensional space, then defines a hyper-plane that differentiates the classes. This tool works well for a complex high dimensional graph, however, it could require higher training time when working with a large dataset, and causing error when target classes are overlapping. A previous study indicated this method has an accuracy rate of 79%, and it was the highest among all tested models.[5]
For this particular project, there are two public solutions which use SVM and neural networks to classify the ingredients. In order to fully understand the tools of classification, we would like to implement different classifiers to test the accuracy rate of each model and report our results.
Despite the existing solution with SVM and neural networks, other machine learning algorithms can be implemented in this project, such as Randform Forest, Logistic Regression, or other unsupervised clustering machine learning algorithms. Same as NB, Logistic regression also gives a probabilistic result, which possibly gives a satisfied result. Although DT may not offer a good result based on the current solution, Random Forest is still worth doing for its more powerful model to limit overfitting without substantially increasing error due to bias. Unsupervised Machine Learning algorithms, such as clustering, do not use labeled data to help predict outcomes. However, these algorithms sometimes discover hidden patterns in data without the need for human intervention.




References:
[1] M. Svensson, K. Höök, and R. Cöster, “Designing and evaluating kalas: A social navigation system for food recipes,” ACM Trans. Comput.-Hum. Interact., vol. 12, no. 3, pp. 374–400, Sep. 2005, doi: 10.1145/1096737.1096739.
[2] P. Forbes and M. Zhu, “Content-boosted matrix factorization for recommender systems: experiments with recipe recommendation,” 2011. doi: 10.1145/2043932.2043979.
[3] H. Xie, L. Yu, and Q. Li, “A Hybrid Semantic Item Model for Recipe Search by Example,” in 2010 IEEE International Symposium on Multimedia, Dec. 2010, pp. 254–259. doi: 10.1109/ISM.2010.44.
[4] Y. Shidochi, T. Takahashi, I. Ide, and H. Murase, “Finding replaceable materials in cooking recipe texts considering characteristic cooking actions,” in Proceedings of the ACM multimedia 2009 workshop on Multimedia for cooking and eating activities - CEA ’09, Beijing, China, 2009, p. 9. doi: 10.1145/1630995.1630998.
[5] S. Jayaraman, T. Choudhury, and P. Kumar, “Analysis of classification models based on cuisine prediction using machine learning,” in 2017 International Conference On Smart Technologies For Smart Nation (SmartTechCon), Aug. 2017, pp. 1485–1490. doi: 10.1109/SmartTechCon.2017.8358611.
